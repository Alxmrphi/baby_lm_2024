program: src/train_git_base_osf_text.py
name: text_only_training
method: grid
metric:
  goal: minimize
  name: val_loss
parameters:
  lr:
    values: [1e-5]
  batch_size:
    values: [256]
  n_epochs:
    values: [5]
  min_save_every:
    values: [1]
  n_workers:
    values: [25]
  optimizer:
    values: ["adam"]
  dataset_size:
    values: [-1]
  seed:
    values: [0, 1, 2, 3, 4]
  do_curriculum:
    values: [False]  # This is False for standard-finetuning.
  model_name:
    values: ['git']
  model_type:
    values: ['causal_lm']  # Can be 'causal_lm' or 'sequence'.
  max_token_length:
    values: [50]
  initialize_with_text:
    values: [False]
  use_accelerate:
    values: [False]
  fp16:
    values: [True]
  tokenizer_path:
    values: ['./src/tokenizer/hf_wordpiece_tokenizer_from_git/']
    #values: ['./src/tokenizer/hf_wordpiece_tokenizer_from_flamingo/']
  text_init_model_path:
    values: [None]
  load_optimizer:
    values: [False]